{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e24a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (1.10.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (0.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (4.19.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (0.11.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (1.22.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.4.24)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchvision->sentence-transformers) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ab13ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf73812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (C:\\Users\\user\\.cache\\huggingface\\datasets\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "100%|██████████| 3/3 [00:00<00:00, 752.21it/s]\n",
      "Reusing dataset tweet_eval (C:\\Users\\user\\.cache\\huggingface\\datasets\\tweet_eval\\stance_abortion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1002.62it/s]\n",
      "Reusing dataset tweet_eval (C:\\Users\\user\\.cache\\huggingface\\datasets\\tweet_eval\\stance_atheism\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1001.66it/s]\n",
      "Reusing dataset tweet_eval (C:\\Users\\user\\.cache\\huggingface\\datasets\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1001.90it/s]\n",
      "Reusing dataset tweet_eval (C:\\Users\\user\\.cache\\huggingface\\datasets\\tweet_eval\\stance_feminist\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "100%|██████████| 3/3 [00:00<00:00, 758.88it/s]\n",
      "Reusing dataset tweet_eval (C:\\Users\\user\\.cache\\huggingface\\datasets\\tweet_eval\\stance_hillary\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1003.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dataset_1 = load_dataset(\"tweet_eval\", \"sentiment\")\n",
    "dataset_2 = load_dataset(\"tweet_eval\", \"stance_abortion\")\n",
    "dataset_3 = load_dataset(\"tweet_eval\", \"stance_atheism\")\n",
    "dataset_4 = load_dataset(\"tweet_eval\", \"stance_climate\")\n",
    "dataset_5 = load_dataset(\"tweet_eval\", \"stance_feminist\")\n",
    "dataset_5 = load_dataset(\"tweet_eval\", \"stance_hillary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f58338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# show data\n",
    "def show_random_elements(dataset, num_examples=20):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18640e25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ollie Schniederjans joins Paul Dunne &amp;amp; Jordan Niebrugge as the 3rd amateur in the top 10 at #TheOpen2015! Remarkable</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Just want to listen to Iron Maiden's new album all day tomorrow, but I have work and a project to do so\"</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you love the Red Sox, the Grateful Dead and Fenway Park in September...I've got something to share. #GD50 #RexFoundation</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user snopes may be right, but we all know Islam is alive in Dearborn MI  can't deny that  Not sayin'  sign is real, but the threat is!\"</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"If the PLL Halloween special aired THIS Tues. instead of last Tues., I would be even more creeped out considering the next day is Halloween.\"</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If this goes all the way to the 5th.... Odds lie with Murray to take the match. #usopen #SSTennis</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@user Justin bieber is in Mexico city and monterrey performing.  I hope he doesn't ride any buses at night while there...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Guy I will be streaming live tomorrow starting with a little let's play on Minecraft so tweet what u want to see in the world :)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gucci plenty id secret december appear the dual thine concrete on adjuvant into advocating enlivened: cavQCieRU</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marvel\\u2019s Phase Two Kicks Off with \\u2019Iron Man 3\\u2019 Trailer on October 23rd:  Briefly: If Halloween i... -danferguson.me</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Haha the top 5 most popular shirts on the NFL store are all Jarryd Hayne jerseys, Tom Brady is 6th\"</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KEPR: State DOT: Snoqualmie Pass lane closures may cause delays: If a trip over the Cascades via Interstate 90 is in...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>casually sat in the toilet at the hospital on the phone to Harry then Ben\\u002c standard</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@user because it's August 5th and someone threatened to kill harry today at MetLife</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kendrick Lamar KILLED J.Cole in the Black Friday Aswr.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sunnybank's hooker bounces a 45m penalty goal over the posts in the 1st half of extra time.  Score is 28-31 after 80minutes  CARN HEAVIES!!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@user Wayans brothers need to be in the new Friday movie wit Ice Cube, Chris Tucker, and Kevin Hart. No question.\"</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The hidden Budget tax rises George Osborne didn't want you to know about</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Wi. Gov. mansion now a \"\"Waffle House\"\": Scott Walker decides he doesn't want to repeal 14th Amendment via @user</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"May the Almighty God continually bless you Christians In Ghana, Jesus is Alive!! Spread the Word #GospelHaven\"</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset_1['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ac5611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1['train']\n",
    "dataset_1['test']\n",
    "dataset_1['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a92fc2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59899\n",
      "59899\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "texts_stance = []\n",
    "labels_stance = []\n",
    "\n",
    "texts = dataset_1['train']['text'] + dataset_1['test']['text'] + dataset_1['validation']['text']\n",
    "labels = dataset_1['train']['label'] + dataset_1['test']['label'] + dataset_1['validation']['label']\n",
    "\n",
    "texts_stance = dataset_2['train']['text'] + dataset_2['test']['text'] + dataset_2['validation']['text']\\\n",
    "+ dataset_3['train']['text'] + dataset_3['test']['text'] + dataset_3['validation']['text']\\\n",
    "+ dataset_4['train']['text'] + dataset_4['test']['text'] + dataset_4['validation']['text']\\\n",
    "+ dataset_5['train']['text'] + dataset_5['test']['text'] + dataset_5['validation']['text']\n",
    "labels_stance = dataset_2['train']['label'] + dataset_2['test']['label'] + dataset_2['validation']['label']\\\n",
    "+ dataset_3['train']['label'] + dataset_3['test']['label'] + dataset_3['validation']['label']\\\n",
    "+ dataset_4['train']['label'] + dataset_4['test']['label'] + dataset_4['validation']['label']\\\n",
    "+ dataset_5['train']['label'] + dataset_5['test']['label'] + dataset_5['validation']['label']\n",
    "\n",
    "print(len(texts))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec6689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(texts)):\n",
    "    texts[index] = texts[index].replace('…','...')\n",
    "    texts[index] = texts[index].replace('\\n', ' ')\n",
    "    \n",
    "for index in range(len(texts_stance)):\n",
    "    texts_stance[index] = texts_stance[index].replace('…','...')\n",
    "    texts_stance[index] = texts_stance[index].replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5356ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59899\n",
      "\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "temp_stance = []\n",
    "\n",
    "for text, label in zip(texts, labels):\n",
    "    temp.append({'text' : text, 'label' : label})\n",
    "    \n",
    "for text, label in zip(texts_stance, labels_stance):\n",
    "    temp_stance.append({'text' : text, 'label' : label})\n",
    "    \n",
    "print(len(temp))\n",
    "print(temp[0]['text'])\n",
    "print(temp[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a7dd37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" #Refugees should just go home to #Syria \" they said. #Aleppo\n",
      "1\n",
      "21800\n"
     ]
    }
   ],
   "source": [
    "sorted_dict = sorted(temp, key=(lambda x: x['text']))\n",
    "sorted_dict_stance = sorted(temp_stance, key=(lambda x: x['text']))\n",
    "\n",
    "print(sorted_dict[3]['text'])\n",
    "print(sorted_dict[3]['label'])\n",
    "\n",
    "sorted_positive = [x['text'] for x in sorted_dict if x['label'] == 2 and x['text'] <= 'z']\n",
    "sorted_negative = [x['text'] for x in sorted_dict if x['label'] == 0 and x['text'] <= 'z']\n",
    "sorted_positive_stance = [x['text'] for x in sorted_dict_stance if x['label'] == 2 and x['text'] <= 'z']\n",
    "sorted_negative_stance = [x['text'] for x in sorted_dict_stance if x['label'] == 1 and x['text'] <= 'z']\n",
    "\n",
    "sorted_positive += sorted_positive_stance\n",
    "sorted_negative += sorted_negative_stance\n",
    "\n",
    "random_negative = sorted_negative.copy()\n",
    "random.shuffle(random_negative)\n",
    "random.shuffle(sorted_positive) # 주석해제시 랜덤하게 pair\n",
    "print(len(sorted_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5249b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75188084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sent0': \"FUCK YEAH!!! Conor McGregor won!!! He's the champ now!!!\", 'sent1': '\"My column on why Tom Brady speaking Sunday did wonders for everyone, including himself. Onto the Steelers- WEEI |...', 'hard_neg': 'Will Ted Cruz, Jeb Bush, and all the top ten who swore to support the GOP primary winner.....do it.   Looks like they may end with TRUMP! HA'}\n"
     ]
    }
   ],
   "source": [
    "final_dataset = []\n",
    "index_2 = 0\n",
    "\n",
    "for index in range(0, len(sorted_positive) - 1, 2):\n",
    "    final_dataset.append({'sent0' : sorted_positive[index], 'sent1' : sorted_positive[index+1], 'hard_neg' : random_negative[index_2]})\n",
    "    index_2 += 1\n",
    "    \n",
    "random.shuffle(final_dataset)\n",
    "print(final_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae64fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't wait to see my boy Mitchell fight 15th Dec at excel. Anyone want tickets message me. Ricky burns fighting for title @user\n"
     ]
    }
   ],
   "source": [
    "print(final_dataset[7400]['sent0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e823186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# with open('tweeteval_sentiment.csv','w') as f:\n",
    "#     w = csv.writer(f)\n",
    "#     w.writerow(final_dataset[0].keys())\n",
    "#     for i in range(len(finale_dataset)):\n",
    "#         w.writerow(final_dataset[i].values())\n",
    "        \n",
    "labels = ['sent0','sent1','hard_neg']\n",
    "try:\n",
    "    with open('tweeteval_stance.csv', 'w',newline='',encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=labels)\n",
    "        writer.writeheader()\n",
    "        for elem in final_dataset:\n",
    "            writer.writerow(elem)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492733de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
